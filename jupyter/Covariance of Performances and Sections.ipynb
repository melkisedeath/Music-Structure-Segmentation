{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import partitura\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from basismixer.performance_codec import PerformanceCodec, get_performance_codec, to_matched_score\n",
    "from basismixer.performance_codec import tempo_by_average, tempo_by_derivative \n",
    "from tensorly.decomposition import robust_pca\n",
    "import plotly.express as px\n",
    "import metric_learn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Path of the match aligments\n",
    "MATCHSCORE_DIR = os.path.dirname(os.path.dirname(os.getcwd())) + \"\\\\alignments\\\\match_4\\\\\"\n",
    "\n",
    "file_structure = {\n",
    "    \"name\": \"Mozart\",\n",
    "    \"structure\": {\n",
    "        \"a1_1\": (1, 5),\n",
    "        \"a2_1\": (5, 9),\n",
    "        \"a1_2\": (9, 13),\n",
    "        \"a2_2\": (13, 17),\n",
    "        \"a1_3\": (17, 21),\n",
    "        \"a2_3\": (21, 27),\n",
    "        \"a1_4\": (27, 31),\n",
    "        \"a2_4\": (31, 36)\n",
    "    },\n",
    "    \"step\": 1,\n",
    "    \"measure\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_analysis(\n",
    "        attr, stat, note_array, performance_array, duration, forward_step_lim, \n",
    "        step, NUMBER_OF_WINDOWS=1, number_of_stats=1, is_BM=False\n",
    "        ):\n",
    "    '''\n",
    "    A generalized definition for match score analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    attr : function\n",
    "        One of the above functions, i.e. expressiveness_of_segment or tempo_of_segment.\n",
    "    stat : function\n",
    "        A statistical measure, i.e. mean, std or variance. \n",
    "    note_array : structed array\n",
    "        The note_array from the partitura analysis\n",
    "    performance_array : structured array\n",
    "        The note_array from the basis mixer analysis\n",
    "    duration : float\n",
    "        The duration of a piece in seconds\n",
    "    forward_spet_lim : int\n",
    "        The maximum spread of the note array indices we can search for every window\n",
    "    step : float\n",
    "        The step for the analysis window.\n",
    "    NUMBER_OF_WINDOWS : int \n",
    "        How many windows per step (equal to the length of the attr output vector).\n",
    "    number_of_stats : itn\n",
    "    \n",
    "    is_BM : bool\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : array\n",
    "        An array of size len(duration of analysis) N x NUMBER_OF_WINDOWS x NUMBER_OF_WINDOWS.\n",
    "    '''\n",
    "    # normalize duration\n",
    "    duration = duration / step\n",
    "    step_unit = 1\n",
    "    dim = int(round((duration - (NUMBER_OF_WINDOWS * step_unit)) / step_unit) + 1)\n",
    "    # Experimenting with array resolution\n",
    "    if NUMBER_OF_WINDOWS == 1:\n",
    "        X = np.zeros((dim, number_of_stats))\n",
    "    else :\n",
    "        X = np.zeros((dim, NUMBER_OF_WINDOWS, number_of_stats))\n",
    "    index = 0\n",
    "    for i in range(1, dim - 1, step_unit):\n",
    "        fix_start = i * step\n",
    "        if NUMBER_OF_WINDOWS == 1:\n",
    "            x = list()\n",
    "            ind_list = list()\n",
    "            if len(note_array[index:]) > forward_step_lim:\n",
    "                look_in = forward_step_lim + index\n",
    "            else :\n",
    "                look_in = len(note_array)\n",
    "            for ind, note in enumerate(note_array[index:look_in]):\n",
    "                note_start = note[0] # onset\n",
    "                note_end = note[0] + note[1] #onset + duration\n",
    "                fix_end = fix_start + step\n",
    "                # check if note is in window\n",
    "                if (fix_start <= note_start <= fix_end) or (note_start <= fix_start and note_end >= fix_start):\n",
    "                    ind_list.append(ind)\n",
    "                    if is_BM:\n",
    "                        x.append(performance_array[ind]) # Expressive Parameters\n",
    "                    else:    \n",
    "                        x.append(note)\n",
    "            if x != []:\n",
    "                X[i - 1] = attr(x, stat)\n",
    "        else:\n",
    "            for j in range(1, NUMBER_OF_WINDOWS + 1):\n",
    "                x = list()\n",
    "                ind_list = list()\n",
    "                if len(note_array[index:]) > forward_step_lim*j:\n",
    "                    look_in = forward_step_lim * j + index\n",
    "                else:\n",
    "                    look_in = len(note_array)\n",
    "                for ind, note in enumerate(note_array[index:look_in]):\n",
    "                    note_start = note[0] #onset\n",
    "                    note_end = note[0] + note[1] #onset + duration\n",
    "                    fix_end = fix_start + (j * step)\n",
    "                    # check if note is in window\n",
    "                    if (fix_start <= note_start <= fix_end) or (note_start <= fix_start and note_end >= fix_start):\n",
    "                        ind_list.append(ind)\n",
    "                        if is_BM:\n",
    "                            x.append(performance_array[ind]) # Expressive Parameters\n",
    "                        else:    \n",
    "                            x.append(note)\n",
    "                if x != []:\n",
    "                    X[i - 1][j - 1] = attr(x, stat)\n",
    "        if ind_list != []:\n",
    "            index += min(ind_list)\n",
    "    return X\n",
    "\n",
    "def tempo_of_segment(x, stat):\n",
    "    \"\"\"\n",
    "    Tempo feature extraction per windows.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : list(tuples)\n",
    "        A segment of the note_array\n",
    "    stat : function\n",
    "        a statistical function that outputs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    stat(y1), stat(y2) : tuple(float)\n",
    "        The statistics of Vectors y1 and y2\n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "    score_onsets, score_durations, _, performed_onsets, performed_durations, _ = list(zip(*x))   \n",
    "    y1 = tempo_by_average(score_onsets, performed_onsets, score_durations, performed_durations)[0]\n",
    "    y2 = tempo_by_derivative(score_onsets, performed_onsets, score_durations, performed_durations)[0]\n",
    "    return [stat(y1), stat(y2)]\n",
    "\n",
    "def expressiveness_of_segment(x, stat):\n",
    "    \"\"\"\n",
    "    Tempo feature extraction per windows.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : list(tuples)\n",
    "        A segment of the note_array\n",
    "    stat : function\n",
    "        a statistical function that outputs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    stat(beat_period), stat(velocity), stat(timing) : tuple(float)\n",
    "        The statistics of the expressive vectors\n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "    beat_period, velocity, timing, articulation_log = list(zip(*x))   \n",
    "    return [stat(beat_period), stat(velocity), stat(timing)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perform_analysis(file, attr, stat, number_of_windows):\n",
    "    \"\"\"Perform the analysis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        the file name + extension.\n",
    "    attr : function\n",
    "        One of the above functions, i.e. expressiveness_of_segment or tempo_of_segment.\n",
    "    stat : function\n",
    "        A statistical measure, i.e. mean, std or variance. \n",
    "    number_of_windows : \n",
    "        How many windows per step (equal to the length of the attr output vector).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        An array of size len(duration of analysis) N x number_of_windows x number_of_windows.\n",
    "    performance_SSM : np.array\n",
    "        The SSM of X using dot product and robust PCA.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    step = file_structure[\"step\"]\n",
    "    match_fn = MATCHSCORE_DIR + file\n",
    "    ppart, alignment, spart = partitura.load_match(match_fn, create_part=True)\n",
    "    note_array, _ = to_matched_score(spart, ppart, alignment)\n",
    "    parameter_names = ['beat_period', 'velocity', 'timing', 'articulation_log']\n",
    "    pc = get_performance_codec(parameter_names)\n",
    "    performance_array, _ = pc.encode(spart, ppart, alignment)\n",
    "    durations = [n[1] for n in note_array if n[1]!=0]\n",
    "    min_duration = min(durations)\n",
    "    max_duration = max(durations)\n",
    "    max_polyphony = max([len(list(item[1])) for item in itertools.groupby(note_array, key=lambda x: x[0])])\n",
    "    forward_step_lim = int(max_duration / min_duration + max_polyphony)\n",
    "    note_array, performance_array = zip(*sorted(zip(note_array, performance_array), key=lambda note: note[0][0]))\n",
    "    duration = note_array[-1][0] + max_duration - step\n",
    "    \n",
    "    if attr[1] == \"tempo\":\n",
    "        is_BM = False\n",
    "        dummy = note_array[-1]\n",
    "    else:\n",
    "        is_BM = True\n",
    "        dummy = performance_array[-1]\n",
    "    \n",
    "    attr = attr[0]\n",
    "    stat = stat[0]\n",
    "    \n",
    "    number_of_stats = len(attr([dummy], stat))\n",
    "    X = standard_analysis(attr, stat, note_array, performance_array, duration, forward_step_lim, step, number_of_windows, number_of_stats, is_BM)\n",
    "    low_rank_part, sparse_part = robust_pca(X, reg_E=0.04, learning_rate=1.2, n_iter_max=20)\n",
    "    if len(low_rank_part.shape) > 2:\n",
    "        performance_SSM = np.tensordot(low_rank_part, low_rank_part.T)\n",
    "    else:\n",
    "        performance_SSM = np.dot(low_rank_part, low_rank_part.T)\n",
    "\n",
    "    return X, performance_SSM\n",
    "\n",
    "\n",
    "def plot_tsne(X, y, z= None, colormap=plt.cm.Paired):\n",
    "    \"\"\"\n",
    "    Plot the the TSNE of X.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array\n",
    "        Some multidimentional data in an array (N, M)\n",
    "    y : np.array\n",
    "        Labels that are translated to colors\n",
    "    z : np.array\n",
    "        Labels that are translated as positions to the z-axis\n",
    "    \"\"\"\n",
    "    \n",
    "    tsne = TSNE()\n",
    "    X_embedded = tsne.fit_transform(X)\n",
    "\n",
    "    if z == None:\n",
    "        fig = px.scatter(x=X_embedded[:, 0], y=X_embedded[:, 1], color=y)\n",
    "    else: \n",
    "        fig = px.scatter_3d(x=X_embedded[:, 0], y=X_embedded[:, 1], z=z, color=y)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the attributes and statistics\n",
    "attributes = [(lambda x, stat: tempo_of_segment(x, stat), \"tempo\"),\n",
    "              (lambda x, stat: expressiveness_of_segment(x, stat), \"expressive\")\n",
    "             ]\n",
    "statistic_methods = [(lambda y : np.mean(y), \"mean\"),\n",
    "                     (lambda y : np.std(y), \"std\"),\n",
    "                     (lambda y : np.var(y), \"var\")\n",
    "                    ]\n",
    "\n",
    "# Set the number of windows\n",
    "# tempo takes 2, expressiveness 3 and mixed takes 6\n",
    "number_of_windows = 3\n",
    "\n",
    "data = list()\n",
    "labels = list()\n",
    "for file in os.listdir(MATCHSCORE_DIR):\n",
    "    if file.startswith(\"Mozart\") and file.endswith(\".match\"):\n",
    "        X, performance_SSM = perform_analysis(file, attributes[1], statistic_methods[1], number_of_windows)\n",
    "        data.append(X.reshape(X.shape[0], X.shape[1]*X.shape[2]))\n",
    "        labels.append(os.path.splitext(file)[0][-3:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = list()\n",
    "y = list()\n",
    "z = list()\n",
    "k = 0\n",
    "for perf in data:\n",
    "    for section_name, section_coord in file_structure[\"structure\"].items():\n",
    "        step = file_structure[\"step\"]\n",
    "        temp = perf[int((section_coord[0]-1)*6/step) : int((section_coord[1]-1)*6/step)].tolist()\n",
    "        X.append(temp)\n",
    "        y.append(labels[k])\n",
    "        z.append(section_name)\n",
    "    k +=1\n",
    "\n",
    "# Uniformize all windows\n",
    "# the last is the number of attribute vector * the number of windows\n",
    "\n",
    "X_new = np.zeros([len(X),len(max(X, key = lambda x: len(x))), number_of_windows**2]) \n",
    "for i, j in enumerate(X):\n",
    "    X_new[i][0:len(j)] = j\n",
    "    \n",
    "X = X_new.reshape(X_new.shape[0], X_new.shape[1]*X_new.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying Similarity within subsections of Performances\n",
    "\n",
    "Our objective is to find a way to quantify similarity of performances for which we have a matched score.\n",
    "\n",
    "First we have to define similarity in this context :\n",
    "\n",
    "#### Performance Similarity :\n",
    "We define two groups of performance Similarity. \n",
    "- One group consists of Auto-Similarity or similarity between sections of one performance. \n",
    "- The second group consists of similarities between different performances.\n",
    "\n",
    "\n",
    "\n",
    "### MATCH: Music Alignment Tool CHest\n",
    "\n",
    "A match file format is a toolkit for aligning audio recordings of different renditions of the same piece of music.\n",
    "\n",
    "Which means we can relate some aspects of a performance, i.e. local tempo, dynamics, articulation, etc., with the score notation of the performed piece.\n",
    "\n",
    "\n",
    "## Reasons to do this \n",
    "\n",
    "There are several things that motivate this quest for performance similarity: \n",
    "\n",
    "- Generate more accurate performances.\n",
    "- See if repetitions of sections are performed similarly.\n",
    "- Investigate if musical structure (sections, melody, etc.) can be automatically captured by performance aspects. \n",
    "\n",
    "\n",
    "    The merits of a succesfull capture of performance similarity are only up to our imagination of possible usecases.\n",
    "\n",
    "\n",
    "## What questions are we trying to answer ?\n",
    "\n",
    "- What elements affect our perception of performance similarity ?\n",
    "- What makes performances similar ?\n",
    "- How can we measure performance similarity ?\n",
    "\n",
    "## What was our motivation ?\n",
    "\n",
    "Our motivation is the below graph, based on an analysis model I created with the help of the partitura and basis mixer libraries. We analyzed a segment of Mozart's K.331 Piano Sonata performed by 22 different pianists.\n",
    "\n",
    "\n",
    "In the graph below we see an un-supervised grouping of the analysis based on expressive attributes, such as local tempo, velocity, timing, and articulation. Color represents different perfomers and the z axis represents the subsections sections of the musical segment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "cov = metric_learn.Covariance()\n",
    "X_cov = cov.fit_transform(X)\n",
    "\n",
    "pca = PCA(whiten=True)\n",
    "X_pca = pca.fit_transform(X_cov)\n",
    "\n",
    "tsne = TSNE()\n",
    "X_embedded = tsne.fit_transform(X_pca)\n",
    "fig = px.scatter_3d(x=X_embedded[:, 0], y=X_embedded[:, 1], z=z, color=y)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "fig = go.Figure(px.scatter_3d(x=X_embedded[:, 0], y=X_embedded[:, 1], z=z, color=y))\n",
    "fig.update_layout(title_text='Covariance_Sampling')\n",
    "                \n",
    "pio.write_html(fig, file='covariance_sampling.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The survey\n",
    "\n",
    "The survey we created is intented to be a guideline for continuing experiments and improving the analysis algorithm.\n",
    "If our method (current or future) agrees with the survey results then we can advance to a full scale cognitive auditory experiment.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
